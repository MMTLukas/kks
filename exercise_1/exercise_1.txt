1. ÜBUNG
1.1. Aufgabe
1.1.2	Ausführungszeit messen: Mit Zeitdifferenzberechnung (timestamp am Anfang und am Ende) innerhalb vom Code, in unterschiedlich möglichen Auflösungen (Sekunde vs. ns).
	Alternativen: Abschätzen anhand Zeitwerte-Tabelle für jeden verwendeten Befehl, Deklaration, etc. oder Ausführungszeit nicht in Sekunden sondern in anderen Maßeinheiten messen (Prozessor-Ticks, …)
1.1.3	Vergleich Funktionen
	time()			- Vorteile: Gibt Zeit in Sekunden zurück, wall clock time
				- Nachteile: Zeit nur in Sekunden, Messung anhand der System Uhr

	clock_gettime()		- Vorteile: Zeit in ns, mehrere Uhren sind möglich
				- Nachteile: Messung anhand der System Uhr, manuelle Zeitumstellung wirkt, sich auf absolute Timer aus, benötigt ID der Uhr als Parameter, POSIX only

	clock()			- Vorteile: Berechnet Zeit für das bisherige Bearbeiten des Programms durch den Prozessor (processor time), Zeit in ns
				- Nachteile: Gibt nur eine Abschätzung zurück, misst processor time

	rdtsc			- Vorteile: Hohe Auflösung, wenig Overhead, misst Performance und/oder Zeit
				- Nachteile: Ungenau bei multiple CPUS aufgrund fehlender Synchronisierung

1.1.4 processor time: Die Zeit in der der Prozessor aktiv an einer Aufgabe arbeitet (z.B. exklusive Wartezeiten). Bei parallel ausgeführten Programmen sinkt die processor time nicht.
1.1.5 wall clock time: Die reale Zeit für die Dauer zwischen Start und Ende einer Ausführung. Kann durch Multi-Threading verkürzt werden.
1.1.6 Möglichkeiten Speicherverbrauchsmessung: POSIX getrusage von resource.h oder PID auslesen und im System unter /proc/<pid>/maps nachschauen
1.1.7 Erkenntnisse sleep(n):
	- clock_gettime(): Sehr genau, Größe von N wirkt sich auf wall clock time aus, Messung ergibt immer einen Wert größer sleep(n), da Ausführung von Messung scheinbar auch 100µs benötigt.
	- clock(): Größe von N wirkt sich nicht auf processor time aus
	- time():  Größe von N wirkt sich auf wall clock time aus

1.3. Aufgabe

Sortieralgorithmus: 		External Merge Sort
Durchsatz Netzwerk:			Annahme eines firmeninternen Netzes (z.B. im Techno-Z), Glasfaser (1 Gbit/s = 125MB/s)
Durchsatz Festplatten: 		SSD, Durchsatz 6 Gbit/s = 750MB/s, RAID 0, 32x1TB = 32TB (exkl. Betriebssystem)
Durchsatz Arbeitsspeicher: 	DDR3 SDRAM 2133, Transferrate 17066MB/s = 17GB/s, Menge = 32GB (exkl. Betriebssytem)
Durchsatz CPU: 				Intel Xeon E5 2697 v2 = 119 GB/s
Speicherverbrauch: 			Durchschnittliche Länge einer E-Mail-Adresse: 19 Zeichen, Format ASCII (7-Bit pro Zeichen) = 19*7bit = 133 bit = 16,625 Byte, Anzahl an E-Mail-Adressen = 1.924.812.030.075,188 ~= 2 Billionen

Umsetzung:				- Kopieren der Datei über das Netzwerk auf den eigenen Rechner
						- 32TB aufsplitten zu 1000 Files mit 32GB, welche einzeln mit Merge-Sort (Lautzeit n*log(n) im worst-case) sortiert werden
						- Von den 1000 Files werden 1000 Chunks in der Größe von 32MB eingelesen und mit Merge-Sort in einen 32GB großen Buffer geschrieben. 
						- Danach wird der 32GB große Buffer in die finale Datei geschrieben. Finale Größe der Datei ist 32TB.

Benötigte Zeit: 

	- Kopiervorgang (Stream) inkl. Speichern auf lokalem System: 32TB / 125MB/s = 256000s = 71.11h
	- Sortiervorgang:
		- Laufzeit vom Einlesen 1000x 1 File zu je 32 GB ~= 1000 * 43 Sekunden = 43000 Sekunden ~= 11.95 h
			- Pro File benötigte Zeit 269ms (CPU) / 1882ms (RAM) / 42666ms (SSD)
		- Laufzeit vom Sortieren 1000x 1 File zu je 32 GB:
			- 1 File: O(n*log(n)) mit n 1924812030 und pro Sortierschritt ca. 836ns = 14,940 Sekunden = 4,15 h
		- Schreiben und Einlesen von 32TB: 2*716,66 Minuten ~= 23,88 h
		- Laufzeit vom Mergen der 1000 Files:
			- Mergen (Vergleichen von 1000 Einträgen und Verschieben des niedrigsten Eintrages in Buffer) Annahme = 1 Mikro-Sekunde => 26,82 Minuten
			- Schreiben von 32 TB ~= 11.95 h
		- Gesamt: 71,11+11,95+4,15+23,88+0,447+11,95 = 133,487h = 133,5 h = 5,56 Tage = 5 1/2 Tage





